---
title: "Weiterführende Quellen"
description: Quellen zum Vortrag und darüber hinaus
comments: true
hide: false
toc: false
layout: post
hide: false
categories: [Boosting, Ensembles, Quellen]
author: "Alexander Dockhorn"
---

# Im Vortrag benannte Quellen

- Surowiecki, J. (2004). The wisdom of crowds. Why the many are smarter than the few and how collective wisdom shapes business, economies, societies and nations. Abacus
    - das vorgestellte Beispiel und zahlreiche weitere Vergleiche von Gruppen- und Expertenentscheidungen

- Kearns, M. and Valiant, L.G. (1989). Cryptographic limitations on learning Boolean formulae and finite automata. Proceedings of the Twenty-First Annual ACM Symposium on Theory of Computing (pp. 433-444). New York, NY: ACM Press. </li>
    - [https://www.cis.upenn.edu/~mkearns/papers/cryptojacm.pdf">https://www.cis.upenn.edu/~mkearns/papers/cryptojacm.pdf](https://www.cis.upenn.edu/~mkearns/papers/cryptojacm.pdf">https://www.cis.upenn.edu/~mkearns/papers/cryptojacm.pdf)
    - Sind Weak und Strong Learnability unterschiedliche Klassen?

- Schapire, R. E. (1990). *The strength of weak learnability*. Machine learning, 5(2), 197-227.
    - [https://link.springer.com/content/pdf/10.1007/BF00116037.pdf](https://link.springer.com/content/pdf/10.1007/BF00116037.pdf)
    - erste Nachweis von effektiven Ensemblen aus "Weak learnern"

- Freund, Y., & Schapire, R. E. (1997). *A decision-theoretic generalization of on-line learning and an application to boosting*. Journal of computer and system sciences, 55(1), 119-139.
    - [https://www.face-rec.org/algorithms/Boosting-Ensemble/decision-theoretic_generalization.pdf](https://www.face-rec.org/algorithms/Boosting-Ensemble/decision-theoretic_generalization.pdf)
    - Vorstellung des AdaBoost Algorithmus, Gewichtung eines Weak Learners basierend auf seiner Korrektheit

- Llew Mason, Jonathan Baxter, Peter Bartlett, and Marcus Frean (2000); Boosting Algorithms as Gradient Descent, in S. A. Solla, T. K. Leen, and K.-R. Muller, editors, Advances in Neural Information Processing Systems 12, pp. 512-518, MIT Press
    - [https://papers.nips.cc/paper/1999/file/96a93ba89a5b5c6c226e49b88973f46e-Paper.pdf](https://papers.nips.cc/paper/1999/file/96a93ba89a5b5c6c226e49b88973f46e-Paper.pdf)
    - Boosting als Gradientenabstieg im Funktionsraum</li>


# Ensemble Algorithmen

- Schapire, R. E. & Freund, Y. (2012). Boosting: foundations and algorithms. MIT Press
    - [https://mitpress.mit.edu/sites/default/files/titles/content/boosting_foundations_algorithms/chapter005.html](https://mitpress.mit.edu/sites/default/files/titles/content/boosting_foundations_algorithms/chapter005.html)
    - eine alternative Interpretation des AdaBoost Algorthmus und dessen Trainingsverhaltens
    - auch die anderen Kapitel sind sehr zu empfehlen

- Zhang, C., & Ma, Y. (Eds.). (2012). Ensemble Machine Learning. Springer US. [https://doi.org/10.1007/978-1-4419-9326-7](https://doi.org/10.1007/978-1-4419-9326-7)
    - gut verständliche Kapitel zu den Themen:
        - Ensemble Algorithmen (Kapitel 1)
        - Boosting Algorithmen (Kapitel 2)
        - Random Forests (Kapitel 3)


# Generelle Bücher zum Thema "Intelligent Data Analytics"

Die folgenden beiden Bücher repräsentieren gut verständliche Einführungen in Methoden der künstlichen Intelligenz und der intelligenten Datenanalyse. Da keine Web-Version verfügbar ist, kann ich nur auf die Universitätsbibliothek verweisen.

- Russell, J. S., & Norvig, P. (2003). Artificial Intelligence: A Modern Approach. In Artificial Intelligence. https://doi.org/10.1017/S0269888900007724
    - [https://find.ub.uni-rostock.de/id%7Bcolon%7D359882528](https://find.ub.uni-rostock.de/id%7Bcolon%7D359882528)

- Kruse, R., Borgelt, C., Braune, C., Mostaghim, S., & Steinbrecher, M. (2016). Computational Intelligence. In Computational Intelligence (2nd Editio). Springer London. https://doi.org/10.1007/978-1-4471-7296-3
    - [https://find.ub.uni-rostock.de/id%7Bcolon%7D843911816](https://find.ub.uni-rostock.de/id%7Bcolon%7D843911816)
